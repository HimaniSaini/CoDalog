{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from operator import add\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover, VectorAssembler\n",
    "from pyspark.ml.feature import Word2Vec, Word2VecModel\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import folium\n",
    "import html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path\n",
    "data = '/Users/jerrygeorge/Desktop/finalproj/data/'\n",
    "model = '/Users/jerrygeorge/Desktop/finalproj/model/'\n",
    "output = '/Users/jerrygeorge/Desktop/finalproj/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "bus_df = spark.read.parquet(data + 'business.parquet')\n",
    "user_df = spark.read.parquet(data + 'users.parquet')\n",
    "rev_df = spark.read.parquet(data + '1.parquet',data +'2.parquet',data +'3.parquet',data +'4.parquet',data +'5.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bus_df.createOrReplaceTempView(\"businesses\")\n",
    "user_df.createOrReplaceTempView(\"users\")\n",
    "rev_df.createOrReplaceTempView(\"reviews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         business_id|         review_text|\n",
      "+--------------------+--------------------+\n",
      "|0W4lkclzZThpx3V65...|Love the staff, l...|\n",
      "|AEx2SYEUJmTxVVB18...|Super simple plac...|\n",
      "|VR6GpWIda3SfvPC-l...|Small unassuming ...|\n",
      "|CKC0-MOWMqoeWf6s-...|Lester's is locat...|\n",
      "|ACFtxLv8pGrrxMm6E...|Love coming here....|\n",
      "|s2I_Ni76bjJNK9yG6...|Had their chocola...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt = spark.sql(\"SELECT business_id, review_text FROM reviews\")\n",
    "rt.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = rt.rdd\n",
    "rb_rdd = rt.map(tuple).reduceByKey(add)  \n",
    "rb = spark.createDataFrame(rb_rdd)\n",
    "rb = rb \\\n",
    "                            .withColumnRenamed('_1', 'business_id') \\\n",
    "                            .withColumnRenamed('_2', 'text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build the pipeline \n",
    "regexTokenizer = RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'text', outputCol = 'token')\n",
    "stopWordsRemover = StopWordsRemover(inputCol = 'token', outputCol = 'nostopwrd')\n",
    "countVectorizer = CountVectorizer(inputCol=\"nostopwrd\", outputCol=\"rawFeature\")\n",
    "iDF = IDF(inputCol=\"rawFeature\", outputCol=\"idf_vec\")\n",
    "word2Vec = Word2Vec(vectorSize = 100, minCount = 5, inputCol = 'nostopwrd', outputCol = 'word_vec', seed=123)\n",
    "vectorAssembler = VectorAssembler(inputCols=['idf_vec', 'word_vec'], outputCol='comb_vec')\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopWordsRemover, countVectorizer, iDF, word2Vec, vectorAssembler])\n",
    "\n",
    "# fit the model\n",
    "pipeline_modl = pipeline.fit(reviews_by_business_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb1 = pipeline_mdl.transform(rb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb1.select( 'text', 'nostopwrd', 'idf_vec', 'word_vec', 'comb_vec').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cosine(v1, v2): \n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / np.sqrt(np.dot(v2, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bv = rb1.select('business_id', 'word_vec').rdd.map(lambda x: (x[0], x[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SimBusiness(ids, lim=10):\n",
    "    \n",
    "    schema = StructType([   \n",
    "                            StructField(\"business_id\", StringType(), True)\n",
    "                            ,StructField(\"score\", IntegerType(), True)\n",
    "                            ,StructField(\"input_business_id\", StringType(), True)\n",
    "                        ])\n",
    "    \n",
    "    sd = spark.createDataFrame([], schema)\n",
    "    \n",
    "    for idd in ids:\n",
    "        \n",
    "        iiv = [(r[1]) for r in bv if r[0] == idd][0]\n",
    "        \n",
    "\n",
    "        sbr = sc.parallelize((i[0], float(Cosine(iv, i[1]))) for i in bv)\n",
    "\n",
    "        sbd = spark.createDataFrame(sbr) \\\n",
    "            .withColumnRenamed('_1', 'business_id') \\\n",
    "            .withColumnRenamed('_2', 'score') \\\n",
    "            .orderBy(\"score\", ascending = False)\n",
    "            \n",
    "        sbd = sbd.filter(col(\"business_id\") != b_id).limit(lim)\n",
    "        sbd = sbd.withColumn('input_business_id', lit(idd))\n",
    "        \n",
    "        sbd = sbd \\.union(sbd)\n",
    "        \n",
    "    \n",
    "    return sbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Business(ib):\n",
    "    \n",
    "    a = ib.alias(\"a\")\n",
    "    b = bd.alias(\"b\")\n",
    "    \n",
    "    return a.join(b, col(\"a.business_id\") == col(\"b.business_id\"), 'inner') \\\n",
    "             .select([col('a.'+xx) for xx in a.columns] + [col('b.business_name'),col('b.categories'),\n",
    "                                                           col('b.stars'),col('b.review_count'),\n",
    "                                                           col('b.latitude'),col('b.longitude')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showInMap(df):\n",
    "    \n",
    "    mp = folium.Map(location=[39.71, -69.43], zoom_start=10)\n",
    "\n",
    "    for i, r in df.toPandas().iterrows():\n",
    "        folium.Marker(\n",
    "                    location =[r.latitude, r.longitude], \n",
    "                    popup = html.escape(r[\"business_name\"]) + '<br>' + 'Stars: ' + str(r.stars) + '<br>' + 'Reviews: ' + str(r.review_count),    \n",
    "                    icon = folium.Icon(color='green')).add_to(mp)\n",
    "    return mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contentrec(ud, lim=10):\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT distinct business_id FROM reviews  \n",
    "    where stars >= 3.0 \n",
    "    and user_id = \"{}\"\n",
    "    \"\"\".format(ud)\n",
    "\n",
    "    urb = sqlContext.sql(query)\n",
    "    \n",
    "    urb = urb.sample(False, 0.5).limit(5)\n",
    "\n",
    "    urbd = Business(urb)\n",
    "    \n",
    "    # show the sample details\n",
    "    print('\\nSample:')\n",
    "    urbd.select(['business_id', 'business_name', 'categories']).show(truncate = False)\n",
    "\n",
    "    bl = [i.business_id for i in urb.collect()]\n",
    "\n",
    "    #  restaurants similar to the sample\n",
    "    sbd = SimBusiness(bl, sbl)\n",
    "\n",
    "    s = sbd.alias(\"s\")\n",
    "    r = urb.alias(\"r\")\n",
    "    j = s.join(r, col(\"s.business_id\") == col(\"r.business_id\"), 'left_outer') \\\n",
    "         .where(col(\"r.business_id\").isNull()) \\\n",
    "         .select([col('s.business_id'),col('s.score')])\n",
    "\n",
    "    a = j.orderBy(\"score\", ascending = False).limit(sim_bus_limit)\n",
    "\n",
    "    return Business(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# test recoms for a user\n",
    "\n",
    "ud = 'ZWD8UH1T7QXQr0Eq-mcWYg'\n",
    "\n",
    "cd = contentrec(ud)\n",
    "\n",
    "print(\"Businesses recommended\")\n",
    "cd.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showInMap(cd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
